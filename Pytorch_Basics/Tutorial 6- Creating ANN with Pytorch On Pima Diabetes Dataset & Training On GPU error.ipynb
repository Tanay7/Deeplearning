{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running ANN  using GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3070 Ti Laptop GPU'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tanlocal\\anaconda3\\envs\\torch1\\Lib\\site-packages\\torch\\cuda\\memory.py:440: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1=torch.FloatTensor([1.0,2.0,3.0]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('diabetes.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 0\n",
       "Glucose                     0\n",
       "BloodPressure               0\n",
       "SkinThickness               0\n",
       "Insulin                     0\n",
       "BMI                         0\n",
       "DiabetesPedigreeFunction    0\n",
       "Age                         0\n",
       "Outcome                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['Outcome']=np.where(df['Outcome']==1,\"Diabetic\",\"No Diabetic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>No Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>No Diabetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>Diabetic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age      Outcome  \n",
       "0                     0.627   50     Diabetic  \n",
       "1                     0.351   31  No Diabetic  \n",
       "2                     0.672   32     Diabetic  \n",
       "3                     0.167   21  No Diabetic  \n",
       "4                     2.288   33     Diabetic  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df,hue=\"Outcome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop('Outcome',axis=1).values### independent features\n",
    "y=df['Outcome'].values###dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'Diabetic', 'Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic',\n",
       "       'Diabetic', 'Diabetic', 'No Diabetic', 'No Diabetic', 'Diabetic',\n",
       "       'No Diabetic', 'No Diabetic', 'No Diabetic'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Libraries From Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m X_train\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mFloatTensor(X_train)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m      3\u001b[0m X_test\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mFloatTensor(X_test)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m----> 4\u001b[0m y_train\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mLongTensor(y_train)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m      5\u001b[0m y_test\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mLongTensor(y_test)\u001b[38;5;241m.\u001b[39mcuda()\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "##### Creating Tensors\n",
    "X_train=torch.FloatTensor(X_train).cuda()\n",
    "X_test=torch.FloatTensor(X_test).cuda()\n",
    "y_train=torch.LongTensor(y_train).cuda()\n",
    "y_test=torch.LongTensor(y_test).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Creating Modelwith Pytorch\n",
    "\n",
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self,input_features=8,hidden1=20,hidden2=20,out_features=2):\n",
    "        super().__init__()\n",
    "        self.f_connected1=nn.Linear(input_features,hidden1)\n",
    "        self.f_connected2=nn.Linear(hidden1,hidden2)\n",
    "        self.out=nn.Linear(hidden2,out_features)\n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.f_connected1(x))\n",
    "        x=F.relu(self.f_connected2(x))\n",
    "        x=self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "####instantiate my ANN_model\n",
    "torch.manual_seed(20)\n",
    "model=ANN_Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of ANN_Model(\n",
       "  (f_connected1): Linear(in_features=8, out_features=20, bias=True)\n",
       "  (f_connected2): Linear(in_features=20, out_features=20, bias=True)\n",
       "  (out): Linear(in_features=20, out_features=2, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i in model.parameters():\n",
    "    print(i.is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Backward Propogation-- Define the loss_function,define the optimizer\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m i\u001b[38;5;241m=\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m y_pred\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mforward(X_train)\n\u001b[1;32m----> 8\u001b[0m loss\u001b[38;5;241m=\u001b[39mloss_function(y_pred,y_train)\n\u001b[0;32m      9\u001b[0m final_losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch1\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   1180\u001b[0m                            ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction,\n\u001b[0;32m   1181\u001b[0m                            label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch1\\Lib\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\u001b[38;5;28minput\u001b[39m, target, weight, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time=time.time()\n",
    "epochs=10000\n",
    "final_losses=[]\n",
    "for i in range(epochs):\n",
    "    i=i+1\n",
    "    y_pred=model.forward(X_train)\n",
    "    loss=loss_function(y_pred,y_train)\n",
    "    final_losses.append(loss)\n",
    "    if i%10==1:\n",
    "        print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot the loss function\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs),final_losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Prediction In X_test data\n",
    "predictions=[]\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(X_test):\n",
    "        y_pred=model(data)\n",
    "        predictions.append(y_pred.argmax().item())\n",
    "        print(y_pred.argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "score=accuracy_score(y_test,predictions)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save the model\n",
    "torch.save(model,'diabetes.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save And Load the model\n",
    "model=torch.load('diabetes.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predcition of new data point\n",
    "list(df.iloc[0,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### New Data\n",
    "lst1=[6.0, 130.0, 72.0, 40.0, 0.0, 25.6, 0.627, 45.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=torch.tensor(lst1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Predict new data using Pytorch\n",
    "with torch.no_grad():\n",
    "    print(model(new_data))\n",
    "    print(model(new_data).argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
